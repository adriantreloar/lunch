import asyncio
from pathlib import Path

import pandas as pd

from src.lunch.examples.setup_managers import model_manager, version_manager

from src.lunch.examples.insert_dimension_data import insert_dimension_data
from src.lunch.examples.save_fact import save_fact

from src.lunch.storage.persistence.local_file_columnar_fact_data_persistor import (
    LocalFileColumnarFactDataPersistor,
)
from src.lunch.storage.cache.null_fact_data_cache import NullFactDataCache
from src.lunch.storage.serialization.columnar_fact_data_serializer import (
    ColumnarFactDataSerializer,
)
from src.lunch.storage.fact_data_store import FactDataStore
from src.lunch.import_engine.fact_append_planner import FactAppendPlanner
from src.lunch.import_engine.fact_import_optimiser import FactImportOptimiser
from src.lunch.import_engine.fact_import_enactor import FactImportEnactor
from src.lunch.managers.cube_data_manager import CubeDataManager

from src.lunch.model.table_metadata import TableMetadata, TableMetadataTransformer

async def insert_fact_data():

    await insert_dimension_data()
    await save_fact()

    # Create some fact data

    # append it to f_sales


    data = [
        {
            "department_id" : 1,
            "thing 2": 10,
            "sales value": 10.10
        },
        {
            "department_id" : 1,
            "thing 2": 10,
            "sales value": 10.10
        },
        {
            "department_id" : 1,
            "thing 2": 10,
            "sales value": 10.10
        },
    ]

    df_data = pd.DataFrame(data=data)

    # TODO - create the map between data columns and where they will go in the fact star schema model
    # Source should be autogenerated from df_data - we should have a function to do this
    # Target - should be a model pulled from model_manager using get_star_schema_model_by_fact_name("Sales")

    column_mapping = [{"source": ["department_id"],
                        "target": ["Department", "id_"]
                        },
                       {"source": ["thing 2"],
                        "target": ["Time", "thing 2"],
                        },
                       {"source": ["sales value"],
                        # A measure target puts the original value into 'value'
                        # amd the measure id into 'measure dimension'
                        "measure target": ["measures", "sales"],
                        }
                       ]

    source_metadata=TableMetadata(column_names=list(df_data.columns),
                  column_types=list(df_data.dtypes),
                  length=df_data.shape[0])



    fact_data_persistor = LocalFileColumnarFactDataPersistor(
        directory=Path(
            "/home/treloarja/PycharmProjects/lunch/example_output/fact"
        )
    )
    fact_data_cache = NullFactDataCache()
    fact_data_serializer = ColumnarFactDataSerializer(
        persistor=fact_data_persistor
    )

    fact_data_storage = FactDataStore(
        serializer=fact_data_serializer, cache=fact_data_cache
    )

    fact_append_planner = FactAppendPlanner()
    fact_import_optimiser = FactImportOptimiser(
        fact_append_planner=fact_append_planner,
        fact_data_store=fact_data_storage,
        model_manager=model_manager,
    )
    fact_import_enactor = FactImportEnactor()

    cube_data_manager = CubeDataManager(
        model_manager=model_manager,
        fact_data_store=fact_data_storage,
        fact_import_optimiser=fact_import_optimiser,
        fact_import_enactor=fact_import_enactor,
    )


    async with version_manager.read_version() as read_version:

        read_version_sales_star_schema = await model_manager.get_star_schema_model_by_fact_name(name="Sales", version=read_version)

        async with version_manager.write_reference_data_version(
            read_version=read_version
        ) as write_version:

            write_version_sales_star_schema = await model_manager.get_star_schema_model_by_fact_name(name="Sales",
                                                                                                    version=write_version)


            # This is also done in reference_data_manager.update_dimension_from_dataframe()
            # I did it again here just for show
            plan = await fact_import_optimiser.create_dataframe_append_plan(
                read_version_target_model=read_version_sales_star_schema,
                write_version_target_model=write_version_sales_star_schema,
                # TODO replace source_data with metadata that has already been extracted from df_data
                source_metadata=source_metadata,
                column_mapping=column_mapping,
                read_version=read_version,
                write_version=write_version,
            )

            # TODO match this plan with what _enact_plan needs
            print(plan)

            #await cube_data_manager.append_fact_from_dataframe(
            #    plan=plan,
            #    source_data=df_data,
            #    read_version=read_version,
            #    write_version=write_version,
            #)


# And run it
if __name__ == "__main__":
    asyncio.run(insert_fact_data())
